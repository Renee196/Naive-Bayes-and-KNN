{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TlurLX8EYV9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    # Drop unnecessary columns\n",
        "    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "    \n",
        "    # Convert categorical variables to numerical\n",
        "    df['Sex'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
        "    df['Embarked'] = df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
        "    \n",
        "    # Handle missing values\n",
        "    # For example, fill missing ages with the median age\n",
        "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "    # For example, fill missing embarked values with the most frequent value\n",
        "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "    \n",
        "    # Normalize numerical features\n",
        "    df['Age'] = (df['Age'] - df['Age'].mean()) / df['Age'].std()\n",
        "    df['Fare'] = (df['Fare'] - df['Fare'].mean()) / df['Fare'].std()\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "QnUtDqgFLWZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_probabilities(y_train):\n",
        "    class_probabilities = {}\n",
        "    total_samples = len(y_train)\n",
        "    unique_classes = np.unique(y_train)\n",
        "    for class_ in unique_classes:\n",
        "        class_samples = np.sum(y_train == class_)\n",
        "        class_probabilities[class_] = class_samples / total_samples\n",
        "    return class_probabilities"
      ],
      "metadata": {
        "id": "SeWXMnFoLWdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_feature_probabilities(x_train, y_train):\n",
        "    feature_probabilities = {}\n",
        "    unique_classes = np.unique(y_train)\n",
        "    for class_ in unique_classes:\n",
        "        class_indices = np.where(y_train == class_)[0]\n",
        "        class_features = x_train[class_indices]\n",
        "        feature_probabilities[class_] = {\n",
        "            'mean': np.mean(class_features, axis=0),\n",
        "            'std': np.std(class_features, axis=0)\n",
        "        }\n",
        "    return feature_probabilities"
      ],
      "metadata": {
        "id": "YLQyKAf1LWgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_likelihood(x, mean, std):\n",
        "    exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
        "    likelihood = (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
        "    return likelihood"
      ],
      "metadata": {
        "id": "2scBet-xLWiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_naive_bayes(x_test, class_probabilities, feature_probabilities):\n",
        "    predictions = []\n",
        "    for x in x_test:\n",
        "        max_posterior = float('-inf')\n",
        "        predicted_class = None\n",
        "        for class_, class_probability in class_probabilities.items():\n",
        "            class_feature_probs = feature_probabilities[class_]\n",
        "            posterior = np.log(class_probability)\n",
        "            for i in range(len(x)):\n",
        "                likelihood = calculate_likelihood(x[i], class_feature_probs['mean'][i], class_feature_probs['std'][i])\n",
        "                posterior += np.log(likelihood)\n",
        "            if posterior > max_posterior:\n",
        "                max_posterior = posterior\n",
        "                predicted_class = class_\n",
        "        predictions.append(predicted_class)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "1K-qPanVLWlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(point1, point2):\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))"
      ],
      "metadata": {
        "id": "PQSkTPCgLWnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_k_nearest_neighbors(x_train, y_train, x_test, k):\n",
        "    distances = []\n",
        "    for i in range(len(x_train)):\n",
        "        dist = calculate_distance(x_train[i], x_test)\n",
        "        distances.append((dist, y_train[i]))\n",
        "    distances.sort(key=lambda x: x[0])\n",
        "    neighbors = [distance[1] for distance in distances[:k]]\n",
        "    return neighbors\n"
      ],
      "metadata": {
        "id": "jJ-q3NTFLWqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_knn(x_train, y_train, x_test, k):\n",
        "    predictions = []\n",
        "    for x in x_test:\n",
        "        neighbors = get_k_nearest_neighbors(x_train, y_train, x, k)\n",
        "        unique_classes, class_counts = np.unique(neighbors, return_counts=True)\n",
        "        predicted_class = unique_classes[np.argmax(class_counts)]\n",
        "        predictions.append(predicted_class)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "9XnttAimLWv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "gender_submission_df =pd.read_csv('/content/gender_submission.csv')"
      ],
      "metadata": {
        "id": "FZZjgkKtLWyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "train_df = preprocess_data(train_df)\n",
        "test_df = preprocess_data(test_df)\n",
        "#gender_submission_df= preprocess_data(gender_submission_df)"
      ],
      "metadata": {
        "id": "VbIu_-UMLW1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (x) and target variable (y)\n",
        "x_train = train_df.drop('Survived', axis=1).values\n",
        "y_train = train_df['Survived'].values\n",
        "x_test = test_df.values\n",
        "y_test = gender_submission_df['Survived'].values\n",
        "print (len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQdkqqCbLW3n",
        "outputId": "c6cf0285-fc96-4eec-d814-3aa2b7b26625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and predict using Naive Bayes\n",
        "class_probabilities = calculate_class_probabilities(y_train)\n",
        "feature_probabilities = calculate_feature_probabilities(x_train, y_train)\n",
        "nb_predictions = predict_naive_bayes(x_test, class_probabilities, feature_probabilities)\n",
        "print(nb_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgkS9m3kLW6V",
        "outputId": "7bc9da40-6fd6-4dae-e1e5-08dcc09ced25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, None, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and predict using k-NN\n",
        "k = 37  # Example value for k\n",
        "knn_predictions = predict_knn(x_train, y_train, x_test, k)"
      ],
      "metadata": {
        "id": "06xQdcMWLW80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the predictions (example for k-NN)\n",
        "print('k-NN Predictions:', knn_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2NpnCF1LW_3",
        "outputId": "06d9a606-b120-48e0-99d4-d7d4f222b133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN Predictions: [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy for KNN\n",
        "correct=0\n",
        "for i in range (0,len(y_test)):\n",
        "  if y_test[i]==knn_predictions[i]:\n",
        "    correct+=1\n",
        "accuracy=correct/len(y_test)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp0467wTc7Do",
        "outputId": "c4695bfd-2239-4600-c502-c7f4060f6307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.84688995215311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy for Naive Bayes\n",
        "correct=0\n",
        "for i in range (0,len(y_test)):\n",
        "  if y_test[i]==nb_predictions[i]:\n",
        "    correct+=1\n",
        "accuracy=correct/len(y_test)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8bJ86-6eY42",
        "outputId": "0bfd5f72-a42d-46bf-f18c-5d11dae80fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.930622009569378\n"
          ]
        }
      ]
    }
  ]
}